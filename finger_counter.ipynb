{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ed4c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.4)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1763543134.403110  356361 gl_context.cc:369] GL version: 2.1 (2.1 Metal - 88), renderer: Apple M1\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1763543134.432220  356554 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1763543134.451950  356554 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "2025-11-19 17:05:34.617 Python[17194:356361] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n",
      "2025-11-19 17:05:34.617 Python[17194:356361] WARNING: Secure coding is not enabled for restorable state! Enable secure coding by implementing NSApplicationDelegate.applicationSupportsSecureRestorableState: and returning YES.\n",
      "W0000 00:00:1763543137.678728  356558 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "W0000 00:00:1763543137.678728  356558 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pygame\n",
    "\n",
    "pygame.mixer.init()\n",
    "pygame.mixer.music.load(\"sadarkan_aku.wav\")\n",
    "\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "\n",
    "# Load video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize Mediapipe hands\n",
    "with mp_hands.Hands(min_detection_confidence=0.5, min_tracking_confidence=0.5) as hands:\n",
    "    while True:\n",
    "        # Read frame from camera\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Convert image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Flip image horizontally\n",
    "        image = cv2.flip(image, 1)\n",
    "\n",
    "        # Set flag to detect landmarks\n",
    "        results = hands.process(image)\n",
    "\n",
    "        # Draw landmarks on image\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    image, hand_landmarks, mp_hands.HAND_CONNECTIONS)     \n",
    "        \n",
    "        # Detect finger count\n",
    "        finger_count = 0\n",
    "        if results.multi_hand_landmarks:\n",
    "            hand_landmarks = results.multi_hand_landmarks[0]\n",
    "            tip_ids = [4, 8, 12, 16, 20]  # Landmark ids of finger tips\n",
    "            finger_states = []\n",
    "            for tip_id in tip_ids:\n",
    "                finger_tip = hand_landmarks.landmark[tip_id]\n",
    "                finger_mcp = hand_landmarks.landmark[tip_id - 1]\n",
    "                # Check if finger is open or closed\n",
    "                if tip_id==4:\n",
    "                    finger_states.append(finger_tip.x < finger_mcp.x)\n",
    "                else:\n",
    "                    finger_states.append(finger_tip.y < finger_mcp.y)\n",
    "            # Count number of open fingers\n",
    "            finger_count = finger_states.count(True)\n",
    "\n",
    "        # Display finger count on image (large, centered with outline for readability)\n",
    "        text = str(finger_count) if finger_count != 5 else \"JAM LIMA MENTIONED RAHHH\"\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        # Scale and thickness tuned for large display; adjust if it's too big/small for your camera resolution\n",
    "        scale = 2\n",
    "        thickness = 5\n",
    "        # Calculate text size so we can center it\n",
    "        (text_width, text_height), baseline = cv2.getTextSize(text, font, scale, thickness)\n",
    "        x = (image.shape[1] - text_width) // 2\n",
    "        # y is baseline-based: put text vertically centered visually\n",
    "        y = (image.shape[0] + text_height) // 2\n",
    "        # Draw a thick black outline for contrast\n",
    "        cv2.putText(image, text, (x, y), font, scale, (0, 0, 0), thickness + 6, cv2.LINE_AA)\n",
    "        # Draw the colored text on top\n",
    "        cv2.putText(image, text, (x, y), font, scale, (0, 0, 255), thickness, cv2.LINE_AA)\n",
    "\n",
    "        # Display image\n",
    "        # cv2.imshow('Finger Counter', image)\n",
    "\n",
    "        # Play music only while finger_count == 5, stop otherwise\n",
    "        if finger_count == 5:\n",
    "            if not pygame.mixer.music.get_busy():\n",
    "                pygame.mixer.music.play(-1)\n",
    "        else:\n",
    "            if pygame.mixer.music.get_busy():\n",
    "                pygame.mixer.music.stop()\n",
    "\n",
    "        # Check for 'q' key to quit\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release video capture and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bed1e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.11.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
